{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(infile, outfile):\n",
    "    with open(infile, encoding='utf-8') as f, open(outfile, 'w', encoding='utf-8') as fout:\n",
    "        lines = f.readlines()\n",
    "        concepts = {}\n",
    "\n",
    "        for line in lines:\n",
    "            try:\n",
    "                line = eval(line)\n",
    "            except:\n",
    "                print(f\"Skipping line due to eval error: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "            for res in line:\n",
    "                res = res.split('\\n')\n",
    "                for term in res:\n",
    "                    term = term.strip().lower()\n",
    "                    if not term:\n",
    "                        continue\n",
    "\n",
    "                    terms = term.split(':')\n",
    "                    if len(terms) != 2:\n",
    "                        print(f\"Parsing error: term {term}\")\n",
    "                        continue\n",
    "\n",
    "                    concept, epa = terms[0].strip(), terms[1].strip()\n",
    "\n",
    "                    concept = concept.rstrip(']').strip()\n",
    "\n",
    "                    # Replace underscores with spaces to unify the concept name\n",
    "                    concept = concept.replace('_', ' ')\n",
    "\n",
    "                    # Extract numeric identifier and concept\n",
    "                    match = re.search(r'(\\d+#.*)', concept)\n",
    "                    if not match:\n",
    "                        print(f\"Parsing error: concept {concept}\")\n",
    "                        continue\n",
    "\n",
    "                    num_concept = match.group(1)\n",
    "                    epa = epa.strip('[]')\n",
    "\n",
    "                    try:\n",
    "                        epa = float(epa)\n",
    "                    except:\n",
    "                        print(f\"EPA '{epa}' cannot be parsed for term '{term}'\")\n",
    "                        continue\n",
    "\n",
    "                    if num_concept not in concepts:\n",
    "                        concepts[num_concept] = []\n",
    "\n",
    "                    concepts[num_concept].append(epa)\n",
    "\n",
    "        for num_concept in sorted(concepts.keys(), key=lambda x: int(x.split('#')[0])):\n",
    "            if len(concepts[num_concept]) != 5:\n",
    "                print(f\"Concept {num_concept} does not have 5 outputs!\")\n",
    "            else:\n",
    "                num, concept = num_concept.split('#', 1)\n",
    "                epa_values = concepts[num_concept]\n",
    "                fout.write(f\"{num}, {concept}, {epa_values}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error: term ```plaintext\n",
      "Parsing error: term ```\n"
     ]
    }
   ],
   "source": [
    "infile = 'chatgpt_f_A_1_600_714.txt'\n",
    "outfile = 'extracted_f/chatgpt_f_A_1_600_714.txt'\n",
    "Path('extracted').mkdir(parents=True, exist_ok=True)\n",
    "extract(infile, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! for individual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 7 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 添加列名\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 将列表中的内容拆分为多列\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE5\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 7 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('extracted/chatgpt_s1_A_1_0_41.txt', header=None)\n",
    "\n",
    "# 解析方括号中的内容并转换为列表\n",
    "df[2] = df[2].str.strip('[]').str.split(', ')\n",
    "\n",
    "# 添加列名\n",
    "df.columns = ['number', 'concept', 'values']\n",
    "\n",
    "# 将列表中的内容拆分为多列\n",
    "df[['E1', 'E2', 'E3', 'E4', 'E5']] = pd.DataFrame(df['values'].tolist())\n",
    "\n",
    "# 删除原始的values列\n",
    "df.drop(columns=['values'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_change_form(filename):\n",
    "    data = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.split(\",\")\n",
    "            num_concept = parts[0].strip()\n",
    "            concept = parts[1].strip()\n",
    "            epa_values = list(map(float, re.findall(r\"-?\\d+\\.\\d+\", parts[2])))\n",
    "            data.append([num_concept, concept] + epa_values)\n",
    "    \n",
    "    # 提取数字和概念\n",
    "    df = pd.DataFrame(data, columns=[\"number\", \"concept\"] + [\"E1\", \"E2\", \"E3\", \"E4\", \"E5\"])\n",
    "\n",
    "    # 按照数字#概念将数字和概念拆分为两列\n",
    "    df[['number', 'concept']] = df['number'].str.split('#', expand=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "7 columns passed, passed data had 3 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 7 columns passed, passed data had 3 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_e \u001b[38;5;241m=\u001b[39m \u001b[43mdata_change_form\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mextracted/chatgpt_s1_E_1_0_41.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 13\u001b[0m, in \u001b[0;36mdata_change_form\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend([num_concept, concept] \u001b[38;5;241m+\u001b[39m epa_values)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 提取数字和概念\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcept\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 按照数字#概念将数字和概念拆分为两列\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\frame.py:809\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 809\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    817\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    818\u001b[0m         arrays,\n\u001b[0;32m    819\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    822\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    823\u001b[0m     )\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32md:\\python\\python3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 7 columns passed, passed data had 3 columns"
     ]
    }
   ],
   "source": [
    "df_e = data_change_form('extracted/chatgpt_s1_E_1_0_41.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from files\n",
    "df_e = data_change_form('extracted/chatgpt_s1_E_1_0_41.txt', include_metadata=True)\n",
    "df_p = data_change_form('extracted/chatgpt_s1_P_1_0_41.txt', include_metadata=False)\n",
    "df_a = data_change_form('extracted/chatgpt_s1_A_1_0_41.txt', include_metadata=False)\n",
    "\n",
    "# Rename columns for df2 and df3\n",
    "df_p.columns = [f\"P{i+1}\" for i in range(df_p.shape[1])]\n",
    "df_a.columns = [f\"A{i+1}\" for i in range(df_a.shape[1])]\n",
    "\n",
    "# Merge dataframes on the index\n",
    "combined_df = pd.concat([df_e, df_p, df_a], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number                                concept   E1\n",
      "0       0                      un bateau de fret  0.5\n",
      "1       1                           une épicerie  2.0\n",
      "2       2           supplier qqn. de faire qqch. -1.0\n",
      "3       3                         une transgenre  1.5\n",
      "4       4                          un kidnappeur -4.0\n",
      "5       5                          déranger qqn. -2.5\n",
      "6       6  augmenter la distance avec qqn./qqch. -2.0\n",
      "7       7                 une conductrice de bus  2.0\n",
      "8       8                 un magasin de lingerie  2.5\n",
      "9       9                            une fumeuse -1.0\n",
      "10     10                   un palais de justice  1.5\n",
      "11     11                           un casse cou  0.5\n",
      "12     12                             un aveugle  0.0\n",
      "13     13                  un assistant dentaire  2.5\n",
      "14     14                         un homme queer  2.0\n",
      "15     15                           un casse cou  0.5\n",
      "16     16                         un homme queer  2.0\n",
      "17     17                           gronder qqn. -1.5\n",
      "18     18                    un salon de massage  1.5\n",
      "19     19                               un motel  1.0\n",
      "20     20               négocier qqch. avec qqn.  1.5\n",
      "21     21                    une femme asexuelle  2.5\n",
      "22     22           en vouloir à qqn. pour qqch. -2.5\n",
      "23     23             un travailleur occasionnel  1.5\n",
      "24     24                  une victime masculine  0.0\n",
      "25     25                    la demeure du maire  1.5\n",
      "26     26                   un repère de junkies -3.0\n",
      "27     27                   un cabinet d'avocats  1.0\n",
      "28     28                         un homme queer  2.0\n",
      "29     29                          une concierge  0.0\n",
      "30     30                     un homme handicapé  0.0\n",
      "31     31                       danser avec qqn.  3.0\n",
      "32     32                           choquer qqn. -3.0\n",
      "33     33                     frapper qqn./qqch. -4.0\n",
      "34     34                  un assistant dentaire  2.5\n",
      "35     35                        haïr qqch./qqn. -4.0\n",
      "36     36                             un sadique -4.0\n",
      "37     37                           un snack-bar  1.0\n",
      "38     38                         une tiny house  2.0\n",
      "39     39                   s'associer avec qqn.  2.0\n",
      "40     40                      une maison hantée  1.0\n"
     ]
    }
   ],
   "source": [
    "print(df_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number                                concept   E1   P1   A1\n",
      "0       0                      un bateau de fret  0.5  0.0 -3.0\n",
      "1       1                           une épicerie  2.0  0.0  0.0\n",
      "2       2           supplier qqn. de faire qqch. -1.0 -1.0  1.0\n",
      "3       3                         une transgenre  1.5  0.0  0.0\n",
      "4       4                          un kidnappeur -4.0  4.0  3.0\n",
      "5       5                          déranger qqn. -2.5 -1.0  2.0\n",
      "6       6  augmenter la distance avec qqn./qqch. -2.0 -1.0 -2.0\n",
      "7       7                 une conductrice de bus  2.0  0.0 -1.0\n",
      "8       8                 un magasin de lingerie  2.5  0.0  1.0\n",
      "9       9                            une fumeuse -1.0 -2.0  1.0\n",
      "10     10                   un palais de justice  1.5  2.0 -2.0\n",
      "11     11                           un casse cou  0.5  2.0  3.0\n",
      "12     12                             un aveugle  0.0 -2.0 -1.0\n",
      "13     13                  un assistant dentaire  2.5 -1.0  0.0\n",
      "14     14                         un homme queer  2.0  0.0  0.0\n",
      "15     15                           un casse cou  0.5  2.0  3.0\n",
      "16     16                         un homme queer  2.0  0.0  0.0\n",
      "17     17                           gronder qqn. -1.5 -1.0  2.0\n",
      "18     18                    un salon de massage  1.5 -1.0 -2.0\n",
      "19     19                               un motel  1.0 -1.0  0.0\n",
      "20     20               négocier qqch. avec qqn.  1.5  0.0 -1.0\n",
      "21     21                    une femme asexuelle  2.5  0.0  0.0\n",
      "22     22           en vouloir à qqn. pour qqch. -2.5 -2.0  2.0\n",
      "23     23             un travailleur occasionnel  1.5  0.0 -1.0\n",
      "24     24                  une victime masculine  0.0 -3.0 -2.0\n",
      "25     25                    la demeure du maire  1.5  3.0 -1.0\n",
      "26     26                   un repère de junkies -3.0 -3.0  3.0\n",
      "27     27                   un cabinet d'avocats  1.0  0.0 -2.0\n",
      "28     28                         un homme queer  2.0  0.0  0.0\n",
      "29     29                          une concierge  0.0 -1.0 -1.0\n",
      "30     30                     un homme handicapé  0.0 -2.0 -1.0\n",
      "31     31                       danser avec qqn.  3.0  1.0  1.0\n",
      "32     32                           choquer qqn. -3.0  1.0  2.0\n",
      "33     33                     frapper qqn./qqch. -4.0  2.0  3.0\n",
      "34     34                  un assistant dentaire  2.5 -1.0  0.0\n",
      "35     35                        haïr qqch./qqn. -4.0  2.0  3.0\n",
      "36     36                             un sadique -4.0  3.0  2.0\n",
      "37     37                           un snack-bar  1.0 -1.0  2.0\n",
      "38     38                         une tiny house  2.0 -2.0 -1.0\n",
      "39     39                   s'associer avec qqn.  2.0  1.0  0.0\n",
      "40     40                      une maison hantée  1.0  1.0  4.0\n"
     ]
    }
   ],
   "source": [
    "print(combined_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
